{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2921b8d1",
      "metadata": {
        "id": "2921b8d1"
      },
      "source": [
        "<center><img src=\"https://i.imgur.com/zRrFdsf.png\" width=\"700\"></center>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Mining your GeoDataFrame\n",
        "\n",
        "This final session covers two main topics:\n",
        "\n",
        "* The computation of spatial distances\n",
        "\n",
        "* The computation of spatial indicators from the spatial data\n",
        "\n",
        "Let me first check what I have in the map geopackage file from Brazil, already reprojected:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiona\n",
        "from fiona import listlayers"
      ],
      "metadata": {
        "id": "eFog15Gt2IL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c9dcc4-9289-4217-e54c-a57d200f33f1"
      },
      "id": "eFog15Gt2IL9",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fiona in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona) (2024.8.30)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona) (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d035f11e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d035f11e",
        "outputId": "079eb627-65b1-4153-ac64-8132459f8a80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['country',\n",
              " 'cities',\n",
              " 'rivers',\n",
              " 'states',\n",
              " 'municipalities',\n",
              " 'airports',\n",
              " 'border']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "brazilMapsLink='https://github.com/CienciaDeDatosEspacial/GeoDataFrame_Analytics/raw/main/maps/brazilMaps_5641.gpkg'\n",
        "\n",
        "#layers in maps\n",
        "listlayers(brazilMapsLink)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68188f73",
      "metadata": {
        "id": "68188f73"
      },
      "source": [
        "Let's read in the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71bca363",
      "metadata": {
        "id": "71bca363"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "# guardando cada capa\n",
        "states=gpd.read_file(brazilMapsLink,layer='states')\n",
        "municipalities=gpd.read_file(brazilMapsLink,layer='municipalities')\n",
        "airports=gpd.read_file(brazilMapsLink,layer='airports')\n",
        "rivers=gpd.read_file(brazilMapsLink,layer='rivers')\n",
        "border=gpd.read_file(brazilMapsLink,layer='border')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c567126e",
      "metadata": {
        "id": "c567126e"
      },
      "source": [
        "Now, we are going to add more data. In this [link](https://msi.nga.mil/Publications/WPI) we find the  World Port Index (Pub 150), which contains several data on major ports and terminals world-wide. Let me read the **UpdatedPub150.csv** from a GitHub repo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea0d908f",
      "metadata": {
        "id": "ea0d908f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "portsFileLink=\"https://github.com/CienciaDeDatosEspacial/GeoDataFrame_Analytics/raw/main/data/UpdatedPub150.csv\"\n",
        "infoseaports=pd.read_csv(portsFileLink)\n",
        "\n",
        "#columns available (so many)\n",
        "infoseaports.columns.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ae0e92a",
      "metadata": {
        "id": "6ae0e92a"
      },
      "source": [
        "Let's do some preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42dc537e",
      "metadata": {
        "id": "42dc537e"
      },
      "outputs": [],
      "source": [
        "#rename\n",
        "infoseaports.rename(columns={'Main Port Name':'portName'},inplace=True)\n",
        "#keep few columns\n",
        "infoseaports=infoseaports.loc[:,['portName', 'Country Code','Latitude', 'Longitude']]\n",
        "\n",
        "# we have now\n",
        "infoseaports.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c28b10c1-98ef-49be-9f7e-9cff0f6b91fd",
      "metadata": {
        "id": "c28b10c1-98ef-49be-9f7e-9cff0f6b91fd"
      },
      "outputs": [],
      "source": [
        "# some rows\n",
        "infoseaports.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "810f28f2",
      "metadata": {
        "id": "810f28f2"
      },
      "source": [
        "Let's turn those points into projected spatial object (GDF of points):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d2a73e",
      "metadata": {
        "id": "16d2a73e"
      },
      "outputs": [],
      "source": [
        "#spatial points (unprojected)\n",
        "seaports=gpd.GeoDataFrame(data=infoseaports.copy(),\n",
        "                           geometry=gpd.points_from_xy(infoseaports.Longitude,\n",
        "                                                       infoseaports.Latitude),\n",
        "                          crs=4326)# notice it is unprojected\n",
        "\n",
        "# keep Brazil\n",
        "seaports_bra=seaports[seaports['Country Code']=='Brazil'].copy()\n",
        "\n",
        "# reset indexes\n",
        "seaports_bra.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# reprojecting\n",
        "seaports_bra_5641=seaports_bra.to_crs(5641) # projected crs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5afed0d",
      "metadata": {
        "id": "c5afed0d"
      },
      "source": [
        "Let me plot seaports along with the _large_ airports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd8f3eb",
      "metadata": {
        "id": "efd8f3eb"
      },
      "outputs": [],
      "source": [
        "# subsetting\n",
        "largeAirports=airports[airports['kind']=='large_airport'] #can't use \"airports.type\"\n",
        "largeAirports.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#plotting\n",
        "base=largeAirports.plot(color='red',marker=\"^\")\n",
        "seaports_bra_5641.plot(ax=base,alpha=0.5,markersize=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e33e90a3",
      "metadata": {
        "id": "e33e90a3"
      },
      "source": [
        "# I. MINING SPATIAL LOCATION\n",
        "\n",
        "## Distance between points\n",
        "\n",
        "The easiest way to understand distance is to compute how far two coordinates are from each other.\n",
        "\n",
        "You have the seaports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40daaf71",
      "metadata": {
        "id": "40daaf71"
      },
      "outputs": [],
      "source": [
        "seaports_bra_5641.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a923d850",
      "metadata": {
        "id": "a923d850"
      },
      "source": [
        "... and the large airports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b3058d8",
      "metadata": {
        "id": "8b3058d8"
      },
      "outputs": [],
      "source": [
        "largeAirports.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63843300",
      "metadata": {
        "id": "63843300"
      },
      "source": [
        "If both GDFs have **the same projected CRS**, we can use the *distance()* function. In this case, just two selected points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c53d18",
      "metadata": {
        "id": "d4c53d18"
      },
      "outputs": [],
      "source": [
        "# distance between 'Guarulhos' and 'Dtse / Gegua Oil Terminal'\n",
        "largeAirports.iloc[0].geometry.distance(seaports_bra_5641.iloc[0].geometry)/1000  # in km"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e38446d9",
      "metadata": {
        "id": "e38446d9"
      },
      "source": [
        "What about computing all possible distances between those GDFs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a86921",
      "metadata": {
        "id": "61a86921"
      },
      "outputs": [],
      "source": [
        "#try 1: default\n",
        "seaports_bra_5641.geometry.apply\\\n",
        "(lambda g: largeAirports.geometry.distance(g)/1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde1d24e",
      "metadata": {
        "id": "dde1d24e"
      },
      "outputs": [],
      "source": [
        "# try 2: see names (change indexes)\n",
        "\n",
        "seaports_bra_5641.set_index('portName').geometry.apply\\\n",
        "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0936bad1",
      "metadata": {
        "id": "0936bad1"
      },
      "outputs": [],
      "source": [
        "#try 3: reorder previous output\n",
        "\n",
        "seaports_bra_5641.set_index('portName').geometry.apply\\\n",
        "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
        "sort_index(axis=0).sort_index(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c02e6be",
      "metadata": {
        "id": "3c02e6be"
      },
      "source": [
        "Let's keep the last one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d2f0b5c",
      "metadata": {
        "id": "3d2f0b5c"
      },
      "outputs": [],
      "source": [
        "distanceMatrixKM_sea_air= seaports_bra_5641.set_index('portName').geometry.apply\\\n",
        "                          (lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
        "                          sort_index(axis=0).sort_index(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "481b14df",
      "metadata": {
        "id": "481b14df"
      },
      "source": [
        "This a data frame (pandas), and the names of the facilities are row and column indexes. From this distance matrix we can make some key queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d023731",
      "metadata": {
        "id": "1d023731"
      },
      "outputs": [],
      "source": [
        "# the mean distance from a seaport to all the large airports (sorted)\n",
        "distanceMatrixKM_sea_air.mean(axis=1).sort_values(ascending=True) #axis=0?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a58d83a",
      "metadata": {
        "id": "4a58d83a"
      },
      "source": [
        "Let's compute more stats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a565ab8a",
      "metadata": {
        "id": "a565ab8a"
      },
      "outputs": [],
      "source": [
        "SomeStats=pd.DataFrame()\n",
        "SomeStats['mean']=distanceMatrixKM_sea_air.mean(axis=1)\n",
        "SomeStats['min']=distanceMatrixKM_sea_air.min(axis=1)\n",
        "SomeStats['max']=distanceMatrixKM_sea_air.max(axis=1)\n",
        "\n",
        "# see some\n",
        "SomeStats.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a343ceec",
      "metadata": {
        "id": "a343ceec"
      },
      "source": [
        "We can also use **idxmax** to get the particular locations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce11850",
      "metadata": {
        "id": "3ce11850"
      },
      "outputs": [],
      "source": [
        "# farthest airport to each seaport\n",
        "distanceMatrixKM_sea_air.idxmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab247b61",
      "metadata": {
        "id": "ab247b61"
      },
      "outputs": [],
      "source": [
        "# farthest seaport to each airport\n",
        "distanceMatrixKM_sea_air.idxmax(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d1014f2",
      "metadata": {
        "id": "1d1014f2"
      },
      "outputs": [],
      "source": [
        "# closest airport to each seaport\n",
        "distanceMatrixKM_sea_air.idxmin(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4721bc58",
      "metadata": {
        "id": "4721bc58"
      },
      "outputs": [],
      "source": [
        "# closest seaport to each airport\n",
        "distanceMatrixKM_sea_air.idxmin(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcd7444b-7180-4f2d-9082-e22125534587",
      "metadata": {
        "id": "fcd7444b-7180-4f2d-9082-e22125534587"
      },
      "source": [
        "### Exercises Part I\n",
        "\n",
        "<div class=\"alert-warning\">\n",
        "    \n",
        "Exercises 1,2,3,4 for this part must read you data from GitHub links, and the coding and results must be published using GitHub Pages\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7442ed0f-f773-4371-bc84-f7ffd81b7c85",
      "metadata": {
        "id": "7442ed0f-f773-4371-bc84-f7ffd81b7c85"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "1. Use two maps of points from your country.\n",
        "\n",
        "2. Compute the distance matrix for both maps.\n",
        "\n",
        "3. Select one row of the distance matrix, and plot the two points with the minimal distance on top of the country of your choosing.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cceb84e",
      "metadata": {
        "id": "0cceb84e"
      },
      "source": [
        "## Distance between line and point"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4afe9d",
      "metadata": {
        "id": "4c4afe9d"
      },
      "source": [
        "Let's take a look at the rivers we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c4ccd6",
      "metadata": {
        "id": "c8c4ccd6"
      },
      "outputs": [],
      "source": [
        "rivers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c57145a2",
      "metadata": {
        "id": "c57145a2"
      },
      "outputs": [],
      "source": [
        "#keep one:\n",
        "\n",
        "rivers[rivers.NAME.str.contains('Grande')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67e02737",
      "metadata": {
        "id": "67e02737"
      },
      "source": [
        "You can see that distance works between these two elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874c38f3",
      "metadata": {
        "id": "874c38f3"
      },
      "outputs": [],
      "source": [
        "# distance from each airport to Rio Grande\n",
        "rivers[rivers.NAME.str.contains('Grande')].iloc[0].geometry.distance(largeAirports.set_index('name').geometry)/1000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a669e18",
      "metadata": {
        "id": "3a669e18"
      },
      "source": [
        "Based on what we did previously, let's compute all the distances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3f7a01",
      "metadata": {
        "id": "be3f7a01"
      },
      "outputs": [],
      "source": [
        "distanceMatrixKM_riv_air=rivers.set_index('NAME').geometry.apply\\\n",
        "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
        "sort_index(axis=0).sort_index(axis=1)\n",
        "distanceMatrixKM_riv_air"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf3dafa",
      "metadata": {
        "id": "7cf3dafa"
      },
      "source": [
        "Here, we see one row (river), that tells the distance to each column (large airport):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b23b4d4",
      "metadata": {
        "id": "9b23b4d4"
      },
      "outputs": [],
      "source": [
        "distanceMatrixKM_riv_air.loc['Rio Grande, South America'].sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48194e60",
      "metadata": {
        "id": "48194e60"
      },
      "source": [
        "Let's try a simple plot of the river and the airports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0642c01",
      "metadata": {
        "id": "b0642c01"
      },
      "outputs": [],
      "source": [
        "base=largeAirports.explore(color='red',marker_kwds=dict(radius=10))\n",
        "rivers[rivers.NAME.str.contains('Grande')].explore(m=base)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2211781a",
      "metadata": {
        "id": "2211781a"
      },
      "source": [
        "Now, let's focus on the rivers that belong to a system:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0cb47c7",
      "metadata": {
        "id": "c0cb47c7"
      },
      "outputs": [],
      "source": [
        "rivers[~rivers.SYSTEM.isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4186d59d",
      "metadata": {
        "id": "4186d59d"
      },
      "source": [
        "Let's dissolve the ones that belong to a system into a multiline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1796bcf",
      "metadata": {
        "id": "e1796bcf"
      },
      "outputs": [],
      "source": [
        "systems=rivers.dissolve(by='SYSTEM')\n",
        "systems"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a63e87",
      "metadata": {
        "id": "22a63e87"
      },
      "source": [
        "Let's do some basic formatting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e139d6",
      "metadata": {
        "id": "d4e139d6"
      },
      "outputs": [],
      "source": [
        "# format the GDF:\n",
        "\n",
        "systems.reset_index(drop=False,inplace=True)\n",
        "systems.drop(columns='NAME',inplace=True)\n",
        "\n",
        "# we have\n",
        "systems"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8f39a4",
      "metadata": {
        "id": "2e8f39a4"
      },
      "source": [
        "Another distance matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b69142db",
      "metadata": {
        "id": "b69142db"
      },
      "outputs": [],
      "source": [
        "distanceMatrixKM_sys_air=systems.set_index('SYSTEM').geometry.apply\\\n",
        "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
        "sort_index(axis=0).sort_index(axis=1)\n",
        "\n",
        "distanceMatrixKM_sys_air"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db17f599",
      "metadata": {
        "id": "db17f599"
      },
      "source": [
        "This time, let me get all the minimum distances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f986d3",
      "metadata": {
        "id": "74f986d3"
      },
      "outputs": [],
      "source": [
        "mins=distanceMatrixKM_sys_air.idxmin(axis=\"columns\") # same as axis=1\n",
        "mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43faa293",
      "metadata": {
        "id": "43faa293"
      },
      "outputs": [],
      "source": [
        "# one of them\n",
        "mins.iloc[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e10c68",
      "metadata": {
        "id": "c1e10c68"
      },
      "source": [
        "Let's see now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5690879",
      "metadata": {
        "id": "a5690879"
      },
      "outputs": [],
      "source": [
        "base=systems.explore()\n",
        "# the closest\n",
        "largeAirports[largeAirports.name.isin(mins)].explore(m=base,color='red',marker_kwds=dict(radius=10))\n",
        "# NOT the closest\n",
        "largeAirports[~largeAirports.name.isin(mins)].explore(m=base,color='blue',marker_kwds=dict(radius=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77fb93ce-efb1-4e1a-b1cb-d1da31be655b",
      "metadata": {
        "id": "77fb93ce-efb1-4e1a-b1cb-d1da31be655b"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "1. Use a map of points and a map of lines from your country.\n",
        "\n",
        "2. Compute the distance matrix for both.\n",
        "\n",
        "3. Select one line of the distance matrix, and plot the closests and the farthest point to that line.\n",
        "    \n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebea004d",
      "metadata": {
        "id": "ebea004d"
      },
      "source": [
        "## Polygon to point"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ddf869",
      "metadata": {
        "id": "05ddf869"
      },
      "source": [
        "Let me create some **convex hull**s for our Brazilian system of rivers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838c576f-cc81-4ad1-89e4-8d7361e4fc41",
      "metadata": {
        "id": "838c576f-cc81-4ad1-89e4-8d7361e4fc41"
      },
      "outputs": [],
      "source": [
        "# polygon for each system\n",
        "systems.convex_hull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef415136",
      "metadata": {
        "id": "ef415136"
      },
      "outputs": [],
      "source": [
        "# see them\n",
        "systems.convex_hull.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ec5f8b",
      "metadata": {
        "id": "79ec5f8b"
      },
      "source": [
        "Now, a GDF for the hulls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c44cbd6b",
      "metadata": {
        "id": "c44cbd6b"
      },
      "outputs": [],
      "source": [
        "systems_hulls=systems.convex_hull.to_frame()\n",
        "systems_hulls['system']=['Amazon', 'Parana']\n",
        "systems_hulls.rename(columns={0:'geometry'},inplace=True)\n",
        "systems_hulls=systems_hulls.set_geometry('geometry')\n",
        "systems_hulls.crs=\"EPSG:5641\"\n",
        "systems_hulls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7c6472",
      "metadata": {
        "id": "2c7c6472"
      },
      "source": [
        "Next, the distance matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00059e15",
      "metadata": {
        "id": "00059e15"
      },
      "outputs": [],
      "source": [
        "distanceMatrixKM_sysHull_air=systems_hulls.set_index('system').geometry.apply\\\n",
        "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
        "sort_index(axis=0).sort_index(axis=1)\n",
        "\n",
        "distanceMatrixKM_sysHull_air"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aecbc201",
      "metadata": {
        "id": "aecbc201"
      },
      "source": [
        "All the minimal differences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ee6a63",
      "metadata": {
        "id": "c1ee6a63"
      },
      "outputs": [],
      "source": [
        "mins=distanceMatrixKM_sysHull_air.idxmin(axis=\"columns\")\n",
        "mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4ff09a",
      "metadata": {
        "id": "3d4ff09a"
      },
      "outputs": [],
      "source": [
        "# plotting\n",
        "base=systems_hulls.explore()\n",
        "largeAirports[largeAirports.name.isin(mins)].explore(m=base,color='red',marker_kwds=dict(radius=10))\n",
        "largeAirports[~largeAirports.name.isin(mins)].explore(m=base,color='blue',marker_kwds=dict(radius=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b8e8ffc-55bc-4818-b3b1-e80e52a2123d",
      "metadata": {
        "id": "1b8e8ffc-55bc-4818-b3b1-e80e52a2123d"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "1. Create a HULL for some set of line map.\n",
        "\n",
        "2. Compute the distance matrix between the HULLS and a map of points.\n",
        "\n",
        "3. Plot the HULLS and the points. Show the closest and farthest points to the HULL.\n",
        "    \n",
        "</div>    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f859b3",
      "metadata": {
        "id": "40f859b3"
      },
      "source": [
        "## Distances using _Buffers_\n",
        "\n",
        "A very important case in distance analysis is the use of buffers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66700e80",
      "metadata": {
        "id": "66700e80"
      },
      "outputs": [],
      "source": [
        "# remember:\n",
        "distanceMatrixKM_riv_air"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85e65bb9",
      "metadata": {
        "id": "85e65bb9"
      },
      "outputs": [],
      "source": [
        "# getting a value (it can be any value)\n",
        "distanceMatrixKM_riv_air.loc['Amazon'].min() # I chose min"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab814d95",
      "metadata": {
        "id": "ab814d95"
      },
      "source": [
        "We can use any value to create a buffer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a8d537",
      "metadata": {
        "id": "77a8d537"
      },
      "outputs": [],
      "source": [
        "minMts=distanceMatrixKM_riv_air.loc['Amazon'].min()*1000 # km\n",
        "\n",
        "#the buffer is a polygon:\n",
        "rivers[rivers.NAME=='Amazon'].buffer(distance = minMts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f670518",
      "metadata": {
        "scrolled": true,
        "id": "1f670518"
      },
      "outputs": [],
      "source": [
        "# see buffer:\n",
        "bufferAroundAmazon=rivers[rivers.NAME=='Amazon'].buffer(distance = minMts)\n",
        "bufferAsBase=bufferAroundAmazon.explore(color='red')\n",
        "rivers[rivers.NAME=='Amazon'].explore(m=bufferAsBase,color='blue',style_kwds={'weight':0.5})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4c5369e",
      "metadata": {
        "id": "b4c5369e"
      },
      "source": [
        "Above we used the buffer (red polygon), and the river (blue). Let me add a layer of airports (small ones):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260d5ea9",
      "metadata": {
        "id": "260d5ea9"
      },
      "outputs": [],
      "source": [
        "small_airports=airports[airports['kind']=='small_airport']\n",
        "\n",
        "# plotting\n",
        "rivers[rivers.NAME=='Amazon'].explore(m=bufferAsBase,color='blue',style_kwds={'weight':0.5})\n",
        "small_airports.explore(m=bufferAsBase,color='black')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1298b935",
      "metadata": {
        "id": "1298b935"
      },
      "source": [
        "Now, we can use the buffer (polygon) to keep the airports that are at that particular distance around the river:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf9601fb",
      "metadata": {
        "id": "cf9601fb"
      },
      "outputs": [],
      "source": [
        "\n",
        "riversWithinBuffer=small_airports.clip(mask=bufferAroundAmazon)\n",
        "#\n",
        "riversWithinBuffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d87ddd5",
      "metadata": {
        "id": "4d87ddd5"
      },
      "outputs": [],
      "source": [
        "# plotting the airports within buffer\n",
        "bufferAsBase=bufferAroundAmazon.explore(color='red')\n",
        "rivers[rivers.NAME=='Amazon'].explore(m=bufferAsBase,color='blue',style_kwds={'weight':0.5})\n",
        "riversWithinBuffer.explore(m=bufferAsBase,color='black')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92465afd",
      "metadata": {
        "id": "92465afd"
      },
      "outputs": [],
      "source": [
        "# minimum of all the minimum by row\n",
        "distanceMatrixKM_riv_air.min(axis=1).min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b7f338",
      "metadata": {
        "id": "40b7f338"
      },
      "outputs": [],
      "source": [
        "# using the previous value\n",
        "minMinMts_5=5*distanceMatrixKM_riv_air.min(axis=1).min()*1000\n",
        "\n",
        "\n",
        "allMinBuffer=rivers.buffer(distance = minMinMts_5).explore(color='red')\n",
        "rivers.explore(m=allMinBuffer,color='blue',style_kwds={'weight':0.5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73543dc5",
      "metadata": {
        "id": "73543dc5"
      },
      "outputs": [],
      "source": [
        "# you see all the buffer polygons:\n",
        "riversAll_buf=rivers.buffer(distance = minMinMts_5)\n",
        "riversAll_buf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d6f11a-ec5f-4028-bd3e-bf4cec827168",
      "metadata": {
        "id": "b3d6f11a-ec5f-4028-bd3e-bf4cec827168"
      },
      "source": [
        "Now keep small airports in buffer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36e5d5a2",
      "metadata": {
        "id": "36e5d5a2"
      },
      "outputs": [],
      "source": [
        "allRiversWithinBuffs=small_airports.clip(riversAll_buf)\n",
        "allRiversWithinBuffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0407b593",
      "metadata": {
        "id": "0407b593"
      },
      "outputs": [],
      "source": [
        "# simple\n",
        "base=riversAll_buf.plot(color='yellow')\n",
        "allRiversWithinBuffs.plot(ax=base, color='green', markersize=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3df7ac2",
      "metadata": {
        "id": "c3df7ac2"
      },
      "outputs": [],
      "source": [
        "# folium\n",
        "\n",
        "base=riversAll_buf.explore(color='yellow')\n",
        "allRiversWithinBuffs.explore(m=base, color='green')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323d59e5-3623-4723-81be-f9dbb3cead1a",
      "metadata": {
        "id": "323d59e5-3623-4723-81be-f9dbb3cead1a"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "1. Select a line map and a point one.\n",
        "\n",
        "2. Get the buffer for the lines, select a distance.\n",
        "\n",
        "3. Keep the points that are within the buffer (you might need to play with differn distances until you show something interesting.  \n",
        "    \n",
        "</div>   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae6c03fb-08dc-42d2-999c-ef1315ddb32f",
      "metadata": {
        "id": "ae6c03fb-08dc-42d2-999c-ef1315ddb32f"
      },
      "source": [
        "# II. MINING SPATIAL DATA\n",
        "\n",
        "It is time to use  *dataPeru_indicadores.xlsx* file and the  map of Peruvian districts: *DistritosMap.zip* (zipped shape file).\n",
        "\n",
        "Let's read the data in :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad54a69-3198-4ae0-b561-b786dc0c4c58",
      "metadata": {
        "id": "cad54a69-3198-4ae0-b561-b786dc0c4c58"
      },
      "outputs": [],
      "source": [
        "# data table\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "peruDataLink=\"https://github.com/CienciaDeDatosEspacial/GeoDataFrame_Analytics/raw/main/data/dataPeru_indicadores.xlsx\"\n",
        "datadis=pd.read_excel(peruDataLink,\n",
        "                     dtype={'Ubigeo': object})\n",
        "datadis.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14fb5cdf",
      "metadata": {
        "id": "14fb5cdf"
      },
      "outputs": [],
      "source": [
        "datadis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a840636-49ab-4a6d-9bb6-0e344822e3e5",
      "metadata": {
        "id": "9a840636-49ab-4a6d-9bb6-0e344822e3e5"
      },
      "outputs": [],
      "source": [
        "# map\n",
        "import geopandas as gpd\n",
        "\n",
        "peruMapaDistLink=\"https://github.com/CienciaDeDatosEspacial/GeoDataFrame_Analytics/raw/main/maps/DistritosMap.zip\"\n",
        "\n",
        "mapdis=gpd.read_file(peruMapaDistLink)\n",
        "\n",
        "mapdis.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020e5d2d",
      "metadata": {
        "id": "020e5d2d"
      },
      "outputs": [],
      "source": [
        "mapdis.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e234648d-afd8-49b0-9af6-f02e23461d82",
      "metadata": {
        "id": "e234648d-afd8-49b0-9af6-f02e23461d82"
      },
      "source": [
        "Next we will merge the indicators table into the map."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4de5282-8a5b-45d8-9ced-6c3690a15b42",
      "metadata": {
        "id": "b4de5282-8a5b-45d8-9ced-6c3690a15b42"
      },
      "source": [
        "## Merging\n",
        "\n",
        "When merging, verify the amount of resulting rows first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d0789a7-be19-4eb2-a5d0-66aae882a93f",
      "metadata": {
        "id": "5d0789a7-be19-4eb2-a5d0-66aae882a93f"
      },
      "outputs": [],
      "source": [
        "mapdis.merge(datadis, left_on='DISTRITO', right_on='Distrito').shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f76ed070-616f-4199-a6b0-48f1c80abff6",
      "metadata": {
        "id": "f76ed070-616f-4199-a6b0-48f1c80abff6"
      },
      "source": [
        "The amount of rows increases when merged. Let's do some preprocessing:\n",
        "\n",
        "1. Capitalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d21b724-8212-4bed-88c9-fa9858330f56",
      "metadata": {
        "id": "3d21b724-8212-4bed-88c9-fa9858330f56"
      },
      "outputs": [],
      "source": [
        "# all capitals, no empty spaces before or after.\n",
        "\n",
        "capitalizeColumns=lambda x: x.str.upper().str.strip()\n",
        "datadis[['Provincia','Distrito']]=datadis[['Provincia','Distrito']].apply(capitalizeColumns)\n",
        "mapdis[['PROVINCIA','DISTRITO']]=mapdis[['PROVINCIA','DISTRITO']].apply(capitalizeColumns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ce410db-12e2-405a-83e2-0bf822da1c48",
      "metadata": {
        "id": "0ce410db-12e2-405a-83e2-0bf822da1c48"
      },
      "source": [
        "2. Spanish symbols: The names may come with some symbols that may cause trouble (', ~). Let's get rid of those:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aebbfce-ff05-4b8d-938a-c8c50a21d798",
      "metadata": {
        "id": "0aebbfce-ff05-4b8d-938a-c8c50a21d798"
      },
      "outputs": [],
      "source": [
        "import unidecode\n",
        "\n",
        "\n",
        "byePunctuation=lambda x: unidecode.unidecode(x)\n",
        "datadis[['Provincia','Distrito']]=datadis[['Provincia','Distrito']].map(byePunctuation)  #applymap for olderpandas\n",
        "mapdis[['PROVINCIA','DISTRITO']]=mapdis[['PROVINCIA','DISTRITO']].map(byePunctuation) #applymap for olderpandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d744c9a9-fd9c-4138-b135-4f7d675354ae",
      "metadata": {
        "id": "d744c9a9-fd9c-4138-b135-4f7d675354ae"
      },
      "source": [
        "3. Check uniqueness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c33a551-51a1-4225-86a6-b6d9ae27b12f",
      "metadata": {
        "id": "4c33a551-51a1-4225-86a6-b6d9ae27b12f"
      },
      "outputs": [],
      "source": [
        "datadis.Distrito.duplicated().sum(),mapdis.DISTRITO.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d3ae42-d0ed-4e6c-a114-3517b2351216",
      "metadata": {
        "id": "e8d3ae42-d0ed-4e6c-a114-3517b2351216"
      },
      "source": [
        "The presence of duplicates, forces we create  a column of unique values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50782d60-96b3-4fda-8731-a236a45d8216",
      "metadata": {
        "id": "50782d60-96b3-4fda-8731-a236a45d8216"
      },
      "outputs": [],
      "source": [
        "# concatenating\n",
        "datadis['provDist']=[\"+\".join(pd) for pd in zip (datadis.Provincia,datadis.Distrito)]\n",
        "mapdis['provDist']=[\"+\".join(pd) for pd in zip (mapdis.PROVINCIA,mapdis.DISTRITO)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca51a1a7-9979-4837-b042-4bc7baffbcc1",
      "metadata": {
        "id": "ca51a1a7-9979-4837-b042-4bc7baffbcc1"
      },
      "outputs": [],
      "source": [
        "# the new column looks like this:\n",
        "datadis['provDist'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43aaa1a8-f47d-474c-b465-bada8c5fb40d",
      "metadata": {
        "id": "43aaa1a8-f47d-474c-b465-bada8c5fb40d"
      },
      "source": [
        "Let's find out what is NOT matched between the  tables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ed7646-6dbd-488f-9445-798c3d33d1b7",
      "metadata": {
        "id": "25ed7646-6dbd-488f-9445-798c3d33d1b7"
      },
      "outputs": [],
      "source": [
        "nomatch_df=set(datadis.provDist)- set(mapdis.provDist)\n",
        "nomatch_gdf=set(mapdis.provDist)-set(datadis.provDist)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b8fc82-e9b9-412c-801d-fa0ce0f5f27f",
      "metadata": {
        "id": "29b8fc82-e9b9-412c-801d-fa0ce0f5f27f"
      },
      "source": [
        "This is the amount of rows that could not be matched:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e958add0-261c-42d4-94ca-fc81ad5a1be4",
      "metadata": {
        "id": "e958add0-261c-42d4-94ca-fc81ad5a1be4"
      },
      "outputs": [],
      "source": [
        "len(nomatch_df), len(nomatch_gdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc7a671-ccfa-43e9-99c7-61a44f54fccf",
      "metadata": {
        "id": "8dc7a671-ccfa-43e9-99c7-61a44f54fccf"
      },
      "source": [
        "Let's try renaming the districts using **fuzzy merging**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f6e31a-35da-4cc9-a92c-c1cb1ea09313",
      "metadata": {
        "id": "87f6e31a-35da-4cc9-a92c-c1cb1ea09313"
      },
      "outputs": [],
      "source": [
        "# pick the closest match from nomatch_gdf for a value in nomatch_df\n",
        "from thefuzz import process\n",
        "[(dis,process.extractOne(dis,nomatch_gdf)) for dis in sorted(nomatch_df)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ba7847-e9b3-47fe-9a65-9e93472eddc3",
      "metadata": {
        "id": "13ba7847-e9b3-47fe-9a65-9e93472eddc3"
      },
      "source": [
        "If you are comfortable, you prepare a _dictionary_ of changes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a892fedc-0d65-46bf-9f99-73dc01e409c8",
      "metadata": {
        "id": "a892fedc-0d65-46bf-9f99-73dc01e409c8"
      },
      "outputs": [],
      "source": [
        "# is this OK?\n",
        "\n",
        "changesDis_df={dis:process.extractOne(dis,nomatch_gdf)[0] for dis in sorted(nomatch_df)}\n",
        "changesDis_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a2d81f-93eb-4f2f-b7ec-32faac5be6c0",
      "metadata": {
        "id": "d9a2d81f-93eb-4f2f-b7ec-32faac5be6c0"
      },
      "source": [
        "Now, make the replacements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b7b379-d869-405b-9593-c37afa881943",
      "metadata": {
        "id": "a5b7b379-d869-405b-9593-c37afa881943"
      },
      "outputs": [],
      "source": [
        "datadis.replace({'provDist':changesDis_df},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352c78fe-1b57-474b-b30a-0c7cea12ea4e",
      "metadata": {
        "id": "352c78fe-1b57-474b-b30a-0c7cea12ea4e"
      },
      "source": [
        "Now the merge can happen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48835a7d-b7ea-47e3-b96d-720520109d8a",
      "metadata": {
        "id": "48835a7d-b7ea-47e3-b96d-720520109d8a"
      },
      "outputs": [],
      "source": [
        "datadisMap=mapdis.merge(datadis, on='provDist')\n",
        "# check\n",
        "datadisMap.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1919efb-07bd-4e54-95e7-7a9f4f4e4515",
      "metadata": {
        "id": "c1919efb-07bd-4e54-95e7-7a9f4f4e4515"
      },
      "outputs": [],
      "source": [
        "bye=['Departamento', 'Provincia', 'Distrito','INSTITUCIO','provDist']\n",
        "datadisMap.drop(columns=bye,inplace=True)\n",
        "\n",
        "# keeping\n",
        "datadisMap.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674d3588-fc76-459e-b24d-4b48346060b0",
      "metadata": {
        "id": "674d3588-fc76-459e-b24d-4b48346060b0"
      },
      "source": [
        "### Exercises Part II\n",
        "\n",
        "<div class=\"alert-warning\">\n",
        "    \n",
        "Exercises 5,6,7,8, and 9 for this part must read you data from GitHub links, and the coding and results must be published using GitHub Pages. This is a different project, so those exercises will be published in a different webpage.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "970a0c9c-6318-4c4f-a476-d0ed7e9d916d",
      "metadata": {
        "id": "970a0c9c-6318-4c4f-a476-d0ed7e9d916d"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "1. Get a polygons map of the lowest administrative unit possible.\n",
        "    \n",
        "2. Get a table of variables for those units. At least 3 numerical variables.\n",
        "\n",
        "3. Preprocess both tables and get them ready for merging.\n",
        "\n",
        "4. Do the merging, making the changes needed so that you keep the most columns.\n",
        "    \n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4944a216-12d8-423c-9461-ea8a28c06c69",
      "metadata": {
        "id": "4944a216-12d8-423c-9461-ea8a28c06c69"
      },
      "source": [
        "## Mining one variable\n",
        "\n",
        "In the session on [Intro to GeoDF](https://cienciadedatosespacial.github.io/intro_geodataframe/) we did a lot on this. The main idea was simply to know the behavior of one variable, and plot it as a choropleth map.\n",
        "\n",
        "In this case, **spatial properties** of the data were _NOT_ used at all, for example:\n",
        "\n",
        "1) Descriptive stats would be same in a simple data frame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26d813c9-d01d-40f4-b284-57e9a87e41b9",
      "metadata": {
        "id": "26d813c9-d01d-40f4-b284-57e9a87e41b9"
      },
      "outputs": [],
      "source": [
        "# statistics\n",
        "datadisMap.IDH2019.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d75250",
      "metadata": {
        "id": "a7d75250"
      },
      "source": [
        "2) A histogram would be same in a simple data frame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c75d39e-f2b9-4c7d-9104-eaf64bf70413",
      "metadata": {
        "id": "5c75d39e-f2b9-4c7d-9104-eaf64bf70413"
      },
      "outputs": [],
      "source": [
        "import seaborn as sea\n",
        "\n",
        "sea.histplot(datadisMap.IDH2019, color='yellow')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83007cf5",
      "metadata": {
        "id": "83007cf5"
      },
      "source": [
        "3. Transform and Discretize: We also learned that we could rescale and discretize. But, given this behavior, bell-shaped,  we just need to discretize; which I will simply do using the _fisherjenks_ scheme:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d85b70-12c8-430a-8a85-bdb6b74cafd6",
      "metadata": {
        "id": "31d85b70-12c8-430a-8a85-bdb6b74cafd6"
      },
      "outputs": [],
      "source": [
        "datadisMap.explore(\n",
        "    column=\"IDH2019\",\n",
        "    scheme=\"fisherjenks\",\n",
        "    legend=True,\n",
        "    tooltip=False,\n",
        "    popup=['DEPARTAMEN', 'PROVINCIA', 'DISTRITO'],  # show popup (on-click)\n",
        "    legend_kwds=dict(colorbar=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acb9ee6b-4c2f-4944-8021-b312bd0036d7",
      "metadata": {
        "id": "acb9ee6b-4c2f-4944-8021-b312bd0036d7"
      },
      "source": [
        "## Spatial Properties: determining the _neighborhood_\n",
        "\n",
        "We can compute the neighborhood for each object in a map using different options:\n",
        "\n",
        "1. The polygons that share borders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86843321-186e-4802-aba4-3e91a6b1b14f",
      "metadata": {
        "id": "86843321-186e-4802-aba4-3e91a6b1b14f"
      },
      "outputs": [],
      "source": [
        "from libpysal.weights import Queen, Rook, KNN\n",
        "\n",
        "# rook\n",
        "w_rook = Rook.from_dataframe(datadisMap,use_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885a72d2",
      "metadata": {
        "id": "885a72d2"
      },
      "outputs": [],
      "source": [
        "w_rook.islands"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7486edd8",
      "metadata": {
        "id": "7486edd8"
      },
      "source": [
        "2. The polygons that share at least a point:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb99fe0e-1653-4bc7-b999-89ad9d6db6b4",
      "metadata": {
        "id": "eb99fe0e-1653-4bc7-b999-89ad9d6db6b4"
      },
      "outputs": [],
      "source": [
        "# queen\n",
        "w_queen = Queen.from_dataframe(datadisMap,use_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3b3b88",
      "metadata": {
        "id": "7b3b3b88"
      },
      "outputs": [],
      "source": [
        "w_queen.islands"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea239b8",
      "metadata": {
        "id": "aea239b8"
      },
      "source": [
        "Let me show the islands detected in the previous steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e72fe932",
      "metadata": {
        "id": "e72fe932"
      },
      "outputs": [],
      "source": [
        "datadisMap.iloc[w_queen.islands,:].explore()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c08456cc",
      "metadata": {
        "id": "c08456cc"
      },
      "source": [
        "The presence of _islands_ will be problematic in more complex applications. An alternative is:\n",
        "\n",
        "3) Nearest neighbors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb5474b-da2d-436e-8e76-a4ba23149635",
      "metadata": {
        "id": "dfb5474b-da2d-436e-8e76-a4ba23149635"
      },
      "outputs": [],
      "source": [
        "# k=8 nearest neighbors\n",
        "w_knn8 = KNN.from_dataframe(datadisMap, k=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ea6cdd",
      "metadata": {
        "id": "c9ea6cdd"
      },
      "outputs": [],
      "source": [
        "w_knn8.islands"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a34f9f-ba61-42fe-b6ea-d1f33b536920",
      "metadata": {
        "id": "20a34f9f-ba61-42fe-b6ea-d1f33b536920"
      },
      "source": [
        "Let's understand the differences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d731009a-8404-4f55-bcf0-c392e448dd24",
      "metadata": {
        "id": "d731009a-8404-4f55-bcf0-c392e448dd24"
      },
      "outputs": [],
      "source": [
        "# first district in the GDF:\n",
        "datadisMap.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0c2161-2d95-49f9-b6b6-edef8be67895",
      "metadata": {
        "id": "8f0c2161-2d95-49f9-b6b6-edef8be67895"
      },
      "outputs": [],
      "source": [
        "# amount of neighbors of that district\n",
        "len(w_rook.neighbors[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a26e817-e6b4-4e52-a8ac-5ff1409d6ae6",
      "metadata": {
        "id": "0a26e817-e6b4-4e52-a8ac-5ff1409d6ae6"
      },
      "outputs": [],
      "source": [
        "# details\n",
        "datadisMap.iloc[w_rook.neighbors[0],]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0070510f-20cb-4251-a91b-d7fe14eb6563",
      "metadata": {
        "id": "0070510f-20cb-4251-a91b-d7fe14eb6563"
      },
      "outputs": [],
      "source": [
        "# see the neighbor\n",
        "datadisMap.iloc[w_rook.neighbors[0] ,].plot(facecolor=\"yellow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2533f22-607c-4357-98d8-b5d11bb100d1",
      "metadata": {
        "id": "d2533f22-607c-4357-98d8-b5d11bb100d1"
      },
      "outputs": [],
      "source": [
        "# see whole area\n",
        "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
        "datadisMap.iloc[w_rook.neighbors[0] ,].plot(ax=base,facecolor=\"yellow\",edgecolor='k')\n",
        "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a85f104-870c-41f1-9d38-3a8c60735556",
      "metadata": {
        "id": "0a85f104-870c-41f1-9d38-3a8c60735556"
      },
      "source": [
        "Let's do the same with queen neighbors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff41c1e4-b3e5-4bf8-8e71-f324b0359a0d",
      "metadata": {
        "id": "ff41c1e4-b3e5-4bf8-8e71-f324b0359a0d"
      },
      "outputs": [],
      "source": [
        "# how many\n",
        "len(w_queen.neighbors[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c1d332-ee6f-4618-96c0-1fe9ece97e8f",
      "metadata": {
        "id": "96c1d332-ee6f-4618-96c0-1fe9ece97e8f"
      },
      "outputs": [],
      "source": [
        "# details\n",
        "datadisMap.iloc[w_queen.neighbors[0] ,]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76585272-7591-4b48-b9df-e057995011bc",
      "metadata": {
        "id": "76585272-7591-4b48-b9df-e057995011bc"
      },
      "outputs": [],
      "source": [
        "# see\n",
        "datadisMap.iloc[w_queen.neighbors[0] ,].plot(facecolor=\"yellow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57a6bda9-5af0-4245-92ce-dc6e8f9b9aed",
      "metadata": {
        "id": "57a6bda9-5af0-4245-92ce-dc6e8f9b9aed"
      },
      "outputs": [],
      "source": [
        "# whole area\n",
        "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
        "datadisMap.iloc[w_queen.neighbors[0] ,].plot(ax=base,facecolor=\"yellow\",edgecolor='k')\n",
        "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "315b82b0",
      "metadata": {
        "id": "315b82b0"
      },
      "source": [
        "What about the _eight_ closest ones?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbfa0517-5f72-4c1f-817b-c1df6a4bfaf7",
      "metadata": {
        "id": "cbfa0517-5f72-4c1f-817b-c1df6a4bfaf7"
      },
      "outputs": [],
      "source": [
        "w_knn8.neighbors[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67397df-57e1-4d0e-9a19-30717eec3eca",
      "metadata": {
        "id": "e67397df-57e1-4d0e-9a19-30717eec3eca"
      },
      "outputs": [],
      "source": [
        "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
        "datadisMap.iloc[w_knn8.neighbors[0],].plot(ax=base,facecolor=\"yellow\")\n",
        "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abbbd2a2",
      "metadata": {
        "id": "abbbd2a2"
      },
      "outputs": [],
      "source": [
        "# what about k=4\n",
        "\n",
        "w_knn4 = KNN.from_dataframe(datadisMap, k=4)\n",
        "\n",
        "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
        "datadisMap.iloc[w_knn4.neighbors[0],].plot(ax=base,facecolor=\"yellow\")\n",
        "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd23b4aa-1110-4743-a658-065cd8c925f9",
      "metadata": {
        "id": "cd23b4aa-1110-4743-a658-065cd8c925f9"
      },
      "source": [
        "### Exercise 6\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "        \n",
        "Compute the neighbors of the capital of your country. Plot the results for each of the options.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1899e2-554d-41ce-b38b-0830802ccaae",
      "metadata": {
        "id": "8b1899e2-554d-41ce-b38b-0830802ccaae"
      },
      "source": [
        "## Global spatial correlation\n",
        "\n",
        "If a spatial unit (a row) value in a variable is correlated with values of the neighbors, you know that proximity is interfering with the interpretation.\n",
        "\n",
        "We need the neighboorhood matrix (the weight matrix) to compute spatial correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59143e63-f478-419e-a84a-3617f5c6fc90",
      "metadata": {
        "id": "59143e63-f478-419e-a84a-3617f5c6fc90"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(*w_knn8.full()) # 1 means both are neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0721a79",
      "metadata": {
        "id": "f0721a79"
      },
      "source": [
        "If we standardize by row, the neighboor adds to 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b103792-bf59-4965-bf9a-17d51be8b49b",
      "metadata": {
        "id": "0b103792-bf59-4965-bf9a-17d51be8b49b"
      },
      "outputs": [],
      "source": [
        "# needed for spatial correlation\n",
        "w_knn8.transform = 'R'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57356f5-5d92-48e7-b135-12ce0e0ea09d",
      "metadata": {
        "id": "a57356f5-5d92-48e7-b135-12ce0e0ea09d"
      },
      "outputs": [],
      "source": [
        "# after transformation\n",
        "pd.DataFrame(*w_knn8.full()).head(12).sum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab308c8-26ad-45bb-aa05-5462cd07fc5c",
      "metadata": {
        "id": "dab308c8-26ad-45bb-aa05-5462cd07fc5c"
      },
      "source": [
        "Spatial correlation is measured by the Moran's I statistic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7aaedad-e443-407c-9146-3b87c94f237c",
      "metadata": {
        "id": "a7aaedad-e443-407c-9146-3b87c94f237c"
      },
      "outputs": [],
      "source": [
        "from esda.moran import Moran\n",
        "\n",
        "moranIDH = Moran(datadisMap['IDH2019'], w_knn8)\n",
        "moranIDH.I,moranIDH.p_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f17dab87-7709-405e-afbe-605e10688d18",
      "metadata": {
        "id": "f17dab87-7709-405e-afbe-605e10688d18"
      },
      "source": [
        "A significant Moran's I suggest spatial correlation. Let's see the spatial scatter plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f69e7e5-a4d8-4d31-be91-f295cfb19f68",
      "metadata": {
        "id": "0f69e7e5-a4d8-4d31-be91-f295cfb19f68"
      },
      "outputs": [],
      "source": [
        "from splot.esda import moran_scatterplot\n",
        "\n",
        "fig, ax = moran_scatterplot(moranIDH, aspect_equal=True)\n",
        "ax.set_xlabel('IDH_std')\n",
        "ax.set_ylabel('SpatialLag_IDH_std');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03ccfa77-4bc2-41b0-95d4-7bf743cac51a",
      "metadata": {
        "id": "03ccfa77-4bc2-41b0-95d4-7bf743cac51a"
      },
      "source": [
        "### Exercise 7\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "1. Compute the Moran's coefficient for **one** of your three  numeric variables.\n",
        "    \n",
        "2. Make a scatter plot for each variable.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6a56a5-c9ff-4642-9e57-a98b9195c867",
      "metadata": {
        "id": "2b6a56a5-c9ff-4642-9e57-a98b9195c867"
      },
      "source": [
        "## Local Spatial Correlation\n",
        "\n",
        "We can compute a Local Index of Spatial Association (LISA -local Moran) for each map object. That will help us find spatial clusters (spots) and spatial outliers:\n",
        "\n",
        "* A **hotSpot** is a polygon whose value in the variable is high AND is surrounded with polygons with also high values.\n",
        "\n",
        "* A **coldSpot** is a polygon whose value in the variable is low AND is surrounded with polygons with also low values.\n",
        "\n",
        "* A **coldOutlier** is a polygon whose value in the variable is low BUT is surrounded with polygons with  high values.\n",
        "\n",
        "* A **hotOutlier** is a polygon whose value in the variable is high BUT is surrounded with polygons with  low values.\n",
        "\n",
        "It is also possible that no significant correlation is detected. Let's see those values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0800fd",
      "metadata": {
        "id": "4e0800fd"
      },
      "outputs": [],
      "source": [
        "# A LISA for each district using IDH2019\n",
        "from esda.moran import Moran_Local\n",
        "lisaIDH = Moran_Local(y=datadisMap['IDH2019'], w=w_knn8,seed=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5eaddb-439a-45af-9ca4-c2a833576c2a",
      "metadata": {
        "id": "de5eaddb-439a-45af-9ca4-c2a833576c2a"
      },
      "outputs": [],
      "source": [
        "fig, ax = moran_scatterplot(lisaIDH,p=0.05)\n",
        "ax.set_xlabel('IDH_std')\n",
        "ax.set_ylabel('SpatialLag_IDH_std');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be3025f0",
      "metadata": {
        "id": "be3025f0"
      },
      "source": [
        "You find that a district is in a **quadrant**. If the district is NOT grey, then the LISA is significant. Let's represent that information in a map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5ee422-356e-472a-ba16-7a09f1daeefc",
      "metadata": {
        "id": "5e5ee422-356e-472a-ba16-7a09f1daeefc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from splot.esda import lisa_cluster\n",
        "f, ax = plt.subplots(1, figsize=(12, 12))\n",
        "plt.title('Spots and Outliers')\n",
        "fig = lisa_cluster(lisaIDH,\n",
        "                   datadisMap,ax=ax,\n",
        "                   legend_kwds={'loc': 'center left',\n",
        "                                'bbox_to_anchor': (0.7, 0.6)});\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5acf306-b47c-4914-b050-e2a32b5ad43a",
      "metadata": {
        "id": "c5acf306-b47c-4914-b050-e2a32b5ad43a"
      },
      "source": [
        "Let me add the informtion in lisaIDH to the GeoDF:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b627cccc-7123-45a0-ba53-9f661bac77f7",
      "metadata": {
        "id": "b627cccc-7123-45a0-ba53-9f661bac77f7"
      },
      "outputs": [],
      "source": [
        "# quadrant, # significance\n",
        "lisaIDH.q, lisaIDH.p_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9bedff6-0276-42e5-bc60-118274bf0151",
      "metadata": {
        "id": "b9bedff6-0276-42e5-bc60-118274bf0151"
      },
      "outputs": [],
      "source": [
        "# quadrant: 1 HH,  2 LH,  3 LL,  4 HL\n",
        "pd.Series(lisaIDH.q).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad08c195-9c11-4e38-925f-42aa620a8f9c",
      "metadata": {
        "id": "ad08c195-9c11-4e38-925f-42aa620a8f9c"
      },
      "source": [
        "The info in **lisaIDH.q** can not be used right away, we need to add if the local spatial correlation is significant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b24bb3f7-49c0-4fca-9d36-4b19bf512ac0",
      "metadata": {
        "id": "b24bb3f7-49c0-4fca-9d36-4b19bf512ac0"
      },
      "outputs": [],
      "source": [
        "datadisMap['IDH_quadrant']=[l if p <0.05 else 0 for l,p in zip(lisaIDH.q,lisaIDH.p_sim)  ]\n",
        "datadisMap['IDH_quadrant'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0b86cd7-af02-4667-8cdc-adbcacf236c8",
      "metadata": {
        "id": "b0b86cd7-af02-4667-8cdc-adbcacf236c8"
      },
      "source": [
        "Now, we recode:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e05f70-16d3-4be1-8fd7-89b6be715f00",
      "metadata": {
        "id": "a4e05f70-16d3-4be1-8fd7-89b6be715f00"
      },
      "outputs": [],
      "source": [
        "labels = [ '0 no_sig', '1 hotSpot', '2 coldOutlier', '3 coldSpot', '4 hotOutlier']\n",
        "\n",
        "datadisMap['IDH_quadrant_names']=[labels[i] for i in datadisMap['IDH_quadrant']]\n",
        "\n",
        "datadisMap['IDH_quadrant_names'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54771dcd-a7b6-4429-bd49-3e785f2dd1ba",
      "metadata": {
        "id": "54771dcd-a7b6-4429-bd49-3e785f2dd1ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "# custom colors\n",
        "from matplotlib import colors\n",
        "myColMap = colors.ListedColormap([ 'white', 'pink', 'cyan', 'azure','red'])\n",
        "\n",
        "# Set up figure and ax\n",
        "f, ax = plt.subplots(1, figsize=(12,12))\n",
        "# Plot unique values choropleth including\n",
        "# a legend and with no boundary lines\n",
        "\n",
        "plt.title('Spots and Outliers')\n",
        "\n",
        "datadisMap.plot(column='IDH_quadrant_names',\n",
        "                categorical=True,\n",
        "                cmap=myColMap,\n",
        "                linewidth=0.1,\n",
        "                edgecolor='k',\n",
        "                legend=True,\n",
        "                legend_kwds={'loc': 'center left',\n",
        "                             'bbox_to_anchor': (0.7, 0.6)},\n",
        "                ax=ax)\n",
        "# Remove axis\n",
        "ax.set_axis_off()\n",
        "# Display the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1b9f05-a42d-4360-b403-3934344d4327",
      "metadata": {
        "id": "cf1b9f05-a42d-4360-b403-3934344d4327"
      },
      "source": [
        "### Exercise 8\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "1. Compute the Local Moran for the variables in your data that have significant spatial correlation.\n",
        "    \n",
        "2. Create a new column for each of those variables, with a label ('0 no_sig', '1 hotSpot', '2 coldOutlier', '3 coldSpot', '4 hotOutlier').\n",
        "\n",
        "3. Prepare a map for each of the variables analyzed, showing the spots and outliers.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d5d25af",
      "metadata": {
        "id": "2d5d25af"
      },
      "source": [
        "## Mining several variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51761cd",
      "metadata": {
        "id": "d51761cd"
      },
      "source": [
        "Let me select some columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65be709a",
      "metadata": {
        "id": "65be709a"
      },
      "outputs": [],
      "source": [
        "selected_variables = ['Educ_sec_comp2019_pct',\n",
        "                     'NBI2017_pct',\n",
        "                     'Viv_sin_serv_hig2017_pct']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5934586f",
      "metadata": {
        "id": "5934586f"
      },
      "outputs": [],
      "source": [
        "# see distribution\n",
        "sea.boxplot(datadisMap[selected_variables])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2998446",
      "metadata": {
        "id": "a2998446"
      },
      "source": [
        "Let me check their monotony:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28e81b82",
      "metadata": {
        "id": "28e81b82"
      },
      "outputs": [],
      "source": [
        "datadisMap[selected_variables].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8054af",
      "metadata": {
        "id": "6f8054af"
      },
      "outputs": [],
      "source": [
        "sea.pairplot(\n",
        "    datadisMap[selected_variables], kind=\"reg\", diag_kind=\"kde\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4dcf5c5",
      "metadata": {
        "id": "d4dcf5c5"
      },
      "source": [
        "Here, we can reverse the values of *Educ_sec_comp2019_pct*. First let me standardize:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e87d2a6",
      "metadata": {
        "id": "3e87d2a6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "normalized_data = scaler.fit_transform(datadisMap[selected_variables])\n",
        "sea.displot(pd.melt(pd.DataFrame(normalized_data,columns=selected_variables)),\n",
        "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
        "            log_scale=(False,False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df652d1c",
      "metadata": {
        "id": "df652d1c"
      },
      "source": [
        "Let me create new variables with the standardized values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de888e0",
      "metadata": {
        "id": "2de888e0"
      },
      "outputs": [],
      "source": [
        "# new names\n",
        "selected_variables_new_std=[s+'_std' for s in selected_variables]\n",
        "\n",
        "# add colunms\n",
        "datadisMap[selected_variables_new_std]=normalized_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17fdfd1b",
      "metadata": {
        "id": "17fdfd1b"
      },
      "source": [
        "Now, it is easy to reverse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd6a431",
      "metadata": {
        "id": "dfd6a431"
      },
      "outputs": [],
      "source": [
        "datadisMap['Educ_sec_NO_comp2019_pct_std']=-1*datadisMap.Educ_sec_comp2019_pct_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be16ade3",
      "metadata": {
        "id": "be16ade3"
      },
      "outputs": [],
      "source": [
        "# as a result:\n",
        "selected_variables_new_std = ['Educ_sec_NO_comp2019_pct_std',\n",
        "                     'NBI2017_pct_std',\n",
        "                     'Viv_sin_serv_hig2017_pct_std']\n",
        "sea.pairplot(\n",
        "    datadisMap[selected_variables_new_std], kind=\"reg\", diag_kind=\"kde\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b007649d",
      "metadata": {
        "id": "b007649d"
      },
      "source": [
        "### Conventional Clustering\n",
        "\n",
        "Here, I will use the three variables to create clusters of districts. Let me explore how many clusters could be created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad295ba0",
      "metadata": {
        "id": "ad295ba0"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster import hierarchy as hc\n",
        "\n",
        "\n",
        "Z = hc.linkage(datadisMap[selected_variables_new_std], 'ward')\n",
        "# calculate full dendrogram\n",
        "plt.figure(figsize=(25, 10))\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('cases')\n",
        "plt.ylabel('distance')\n",
        "hc.dendrogram(\n",
        "    Z,\n",
        "    leaf_rotation=90.,  # rotates the x axis labels\n",
        "    leaf_font_size=1,  # font size for the x axis labels\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa45a8ce",
      "metadata": {
        "id": "fa45a8ce"
      },
      "source": [
        "The dendogram recommends three groups. Let me request six.\n",
        "\n",
        "Let me use a common hierarchical technique following a agglomerative approach:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44e4a92",
      "metadata": {
        "id": "b44e4a92"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering as agnes\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(12345)# Set seed for reproducibility\n",
        "\n",
        "# Initialize the algorithm, requesting 6 clusters\n",
        "model = agnes(linkage=\"ward\", n_clusters=6).fit(datadisMap[selected_variables_new_std])\n",
        "\n",
        "# Assign labels to main data table\n",
        "datadisMap[\"hc_ag6\"] = model.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fdcca7",
      "metadata": {
        "id": "16fdcca7"
      },
      "outputs": [],
      "source": [
        "# see distribution of districts\n",
        "datadisMap[\"hc_ag6\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87068ef",
      "metadata": {
        "id": "c87068ef"
      },
      "source": [
        "We could try to find the pattern that created the clusters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757b7721",
      "metadata": {
        "id": "757b7721"
      },
      "outputs": [],
      "source": [
        "datadisMap.groupby(\"hc_ag6\")[selected_variables_new_std].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f58dd2e3",
      "metadata": {
        "id": "f58dd2e3"
      },
      "source": [
        "Let me show you the six groups of districts which have similar behavior in three variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fa279c7",
      "metadata": {
        "id": "8fa279c7"
      },
      "outputs": [],
      "source": [
        "# Set up figure and ax\n",
        "f, ax = plt.subplots(1, figsize=(9, 9))\n",
        "# Plot unique values choropleth including\n",
        "# a legend and with no boundary lines\n",
        "datadisMap.plot(\n",
        "    column=\"hc_ag6\", categorical=True, legend=True, linewidth=0, ax=ax\n",
        ")\n",
        "# Remove axis\n",
        "ax.set_axis_off()\n",
        "# Display the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7386825e",
      "metadata": {
        "id": "7386825e"
      },
      "source": [
        "### Regionalization: Spatial Clustering\n",
        "\n",
        "Spatial clustering or Regionalization will force the contiguity of the polygons to make a cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f9d5a0f",
      "metadata": {
        "id": "2f9d5a0f"
      },
      "outputs": [],
      "source": [
        "# modify previous funtion call to specify cluster model with spatial constraint\n",
        "\n",
        "model_queen = agnes(linkage=\"ward\",\n",
        "                    n_clusters=6,\n",
        "                    connectivity=w_queen.sparse).fit(datadisMap[selected_variables_new_std])\n",
        "# Fit algorithm to the data\n",
        "datadisMap[\"hc_ag6_wQueen\"] = model_queen.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ab01abf",
      "metadata": {
        "id": "1ab01abf"
      },
      "source": [
        "We knew this would happen because we have islands. Then this results may not be satisfactory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b8465df",
      "metadata": {
        "id": "7b8465df"
      },
      "outputs": [],
      "source": [
        "# Set up figure and ax\n",
        "f, ax = plt.subplots(1, figsize=(9, 9))\n",
        "# Plot unique values choropleth including a legend and with no boundary lines\n",
        "datadisMap.plot(\n",
        "    column=\"hc_ag6_wQueen\",\n",
        "    categorical=True,\n",
        "    legend=True,\n",
        "    linewidth=0,\n",
        "    ax=ax,\n",
        ")\n",
        "# Remove axis\n",
        "ax.set_axis_off()\n",
        "# Display the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10da7ec9",
      "metadata": {
        "id": "10da7ec9"
      },
      "source": [
        "We have a couple of KNN weight matrices. Let's use those instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2166b078",
      "metadata": {
        "id": "2166b078"
      },
      "outputs": [],
      "source": [
        "model_wknn8 = agnes(linkage=\"ward\",\n",
        "                    n_clusters=6,\n",
        "                    connectivity=w_knn8.sparse).fit(datadisMap[selected_variables_new_std])\n",
        "datadisMap[\"hc_ag6_wknn8\"] = model_wknn8.labels_\n",
        "\n",
        "\n",
        "model_wknn4 = agnes(linkage=\"ward\",\n",
        "                    n_clusters=6,\n",
        "                    connectivity=w_knn4.sparse).fit(datadisMap[selected_variables_new_std])\n",
        "datadisMap[\"hc_ag6_wknn4\"] = model_wknn4.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0babe9c",
      "metadata": {
        "id": "c0babe9c"
      },
      "outputs": [],
      "source": [
        "# Set up figure and ax\n",
        "f, ax = plt.subplots(1, figsize=(10, 12))\n",
        "# Plot unique values choropleth including a legend and with no boundary lines\n",
        "datadisMap.plot(\n",
        "    column=\"hc_ag6_wknn8\",\n",
        "    categorical=True,\n",
        "    legend=True,\n",
        "    linewidth=0,\n",
        "    ax=ax,\n",
        ")\n",
        "# Remove axis\n",
        "ax.set_axis_off()\n",
        "# Display the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "965da01b",
      "metadata": {
        "id": "965da01b"
      },
      "outputs": [],
      "source": [
        "# Set up figure and ax\n",
        "f, ax = plt.subplots(1, figsize=(10, 12))\n",
        "# Plot unique values choropleth including a legend and with no boundary lines\n",
        "datadisMap.plot(\n",
        "    column=\"hc_ag6_wknn4\",\n",
        "    categorical=True,\n",
        "    legend=True,\n",
        "    linewidth=0,\n",
        "    ax=ax,\n",
        ")\n",
        "# Remove axis\n",
        "ax.set_axis_off()\n",
        "# Display the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1bab781",
      "metadata": {
        "id": "e1bab781"
      },
      "source": [
        "We could evaluate two aspects of these clustering results:\n",
        "\n",
        "* Compactness of cluster shape, using the isoperimetric quotient (IPQ). This compares the area of the region to the area of a circle with the same perimeter as the region. For this measure, more compact shapes have an IPQ closer to 1, whereas very elongated or spindly shapes will have IPQs closer to zero. For the clustering solutions, we would expect the IPQ to be very small indeed, since the perimeter of a cluster/region gets smaller the more boundaries that members share."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e213fe92",
      "metadata": {
        "id": "e213fe92"
      },
      "outputs": [],
      "source": [
        "from esda import shape as shapestats\n",
        "results={}\n",
        "for cluster_type in (\"hc_ag6_wknn4\", \"hc_ag6_wknn8\", \"hc_ag6\"):\n",
        "    # compute the region polygons using a dissolve\n",
        "    regions = datadisMap[[cluster_type, \"geometry\"]].to_crs(24892).dissolve(by=cluster_type)\n",
        "    # compute the actual isoperimetric quotient for these regions\n",
        "    ipqs = shapestats.isoperimetric_quotient(regions)\n",
        "    # cast to a dataframe\n",
        "    result = {cluster_type:ipqs}\n",
        "    results.update(result)\n",
        "# stack the series together along columns\n",
        "pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9599c1e1",
      "metadata": {
        "id": "9599c1e1"
      },
      "source": [
        "An alternative could be _convex_hull_ratio_, simply the division of the area of the cluster by the area of its convex hull."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17091459",
      "metadata": {
        "id": "17091459"
      },
      "outputs": [],
      "source": [
        "from esda import shape as shapestats\n",
        "results={}\n",
        "for cluster_type in (\"hc_ag6_wknn4\", \"hc_ag6_wknn8\", \"hc_ag6\"):\n",
        "    # compute the region polygons using a dissolve\n",
        "    regions = datadisMap[[cluster_type, \"geometry\"]].to_crs(24892).dissolve(by=cluster_type)\n",
        "    # compute the actual convex hull quotient for these regions\n",
        "    chullr = shapestats.convex_hull_ratio(regions)\n",
        "    # cast to a dataframe\n",
        "    result = {cluster_type:chullr}\n",
        "    results.update(result)\n",
        "# stack the series together along columns\n",
        "pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972d9146",
      "metadata": {
        "id": "972d9146"
      },
      "source": [
        "In both cases, the non spatial clusters do better.\n",
        "\n",
        "* Goodness of fit. Here we have two metrics:\n",
        "    - metrics.calinski_harabasz_score\n",
        "    - silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0decf624",
      "metadata": {
        "id": "0decf624"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "fit_scores = []\n",
        "for cluster_type in (\"hc_ag6_wknn4\", \"hc_ag6_wknn8\", \"hc_ag6\"):\n",
        "    # compute the CH score\n",
        "    ch_score = metrics.calinski_harabasz_score(\n",
        "        # using scaled variables\n",
        "        datadisMap[selected_variables_new_std],\n",
        "        # using these labels\n",
        "        datadisMap[cluster_type],\n",
        "    )\n",
        "    sil_score = metrics.silhouette_score(\n",
        "        # using scaled variables\n",
        "        datadisMap[selected_variables_new_std],\n",
        "        # using these labels\n",
        "        datadisMap[cluster_type],\n",
        "    )\n",
        "    # and append the cluster type with the CH score\n",
        "    fit_scores.append((cluster_type, ch_score,sil_score))\n",
        "\n",
        "\n",
        "# re-arrange the scores into a dataframe for display\n",
        "pd.DataFrame(\n",
        "    fit_scores, columns=[\"cluster type\", \"CH score\", \"SIL score\"]\n",
        ").set_index(\"cluster type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61d123df",
      "metadata": {
        "id": "61d123df"
      },
      "source": [
        "Again, the conventional clustering beats the others, as you want bigger values in both.\n",
        "\n",
        "### Exercise 9\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "Use your three variables to carry out the cluster/regional analysis.\n",
        "    \n",
        "</div>\n",
        "\n",
        "\n",
        "### Conventional Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "037f7f72",
      "metadata": {
        "id": "037f7f72"
      },
      "outputs": [],
      "source": [
        "from pysal.model import spreg\n",
        "\n",
        "dep_var_name=['NBI2017_pct']\n",
        "ind_vars_names=['Educ_sec_comp2019_pct','Viv_sin_serv_hig2017_pct']\n",
        "\n",
        "\n",
        "ols_model = spreg.OLS(\n",
        "    # Dependent variable\n",
        "    datadisMap[dep_var_name].values,\n",
        "    # Independent variables\n",
        "    datadisMap[ind_vars_names].values,\n",
        "    w=w_knn8,\n",
        "    spat_diag = True,\n",
        "    moran=True,\n",
        "    # Dependent variable name\n",
        "    name_y=dep_var_name[0],\n",
        "    # Independent variable name\n",
        "    name_x=ind_vars_names)\n",
        "\n",
        "print(ols_model.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb40c6e8",
      "metadata": {
        "id": "fb40c6e8"
      },
      "source": [
        "### Spatial Regression\n",
        "\n",
        "* Spatial Lag Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41165509",
      "metadata": {
        "id": "41165509"
      },
      "outputs": [],
      "source": [
        "moranNBI = Moran(datadisMap[dep_var_name], w_knn8)\n",
        "moranNBI.I,moranNBI.p_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4509eb",
      "metadata": {
        "id": "8b4509eb"
      },
      "outputs": [],
      "source": [
        "fig, ax = moran_scatterplot(moranNBI, aspect_equal=True)\n",
        "ax.set_xlabel('NBI')\n",
        "ax.set_ylabel('SpatialLag_NBI');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d795a272",
      "metadata": {
        "id": "d795a272"
      },
      "outputs": [],
      "source": [
        "lag_model = spreg.ML_Lag(\n",
        "    # Dependent variable\n",
        "    datadisMap[dep_var_name].values,\n",
        "    # Independent variables\n",
        "    datadisMap[ind_vars_names].values,\n",
        "    w=w_knn8,\n",
        "    # Dependent variable name\n",
        "    name_y=dep_var_name[0],\n",
        "    # Independent variable name\n",
        "    name_x=ind_vars_names\n",
        "    )\n",
        "\n",
        "print(lag_model.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a4dcb9",
      "metadata": {
        "id": "08a4dcb9"
      },
      "source": [
        "* Spatial Error Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2152eb",
      "metadata": {
        "id": "3e2152eb"
      },
      "outputs": [],
      "source": [
        "\n",
        "moranError = Moran(ols_model.u, w_knn8)\n",
        "moranError.I,moranError.p_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20f8e94",
      "metadata": {
        "id": "d20f8e94"
      },
      "outputs": [],
      "source": [
        "fig, ax = moran_scatterplot(moranError, aspect_equal=True)\n",
        "ax.set_xlabel('OlsError')\n",
        "ax.set_ylabel('SpatialOlsError');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937f16a6",
      "metadata": {
        "id": "937f16a6"
      },
      "outputs": [],
      "source": [
        "err_model = spreg.ML_Error(\n",
        "    # Dependent variable\n",
        "    datadisMap[dep_var_name].values,\n",
        "    # Independent variables\n",
        "    datadisMap[ind_vars_names].values,\n",
        "    w=w_knn8,\n",
        "    # Dependent variable name\n",
        "    name_y=dep_var_name[0],\n",
        "    # Independent variable name\n",
        "    name_x=ind_vars_names\n",
        "    )\n",
        "\n",
        "print(err_model.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b7175b6",
      "metadata": {
        "id": "3b7175b6"
      },
      "source": [
        "* Spatial Error Regression, correcting heteroscedasticy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d5cab4",
      "metadata": {
        "id": "d8d5cab4"
      },
      "outputs": [],
      "source": [
        "error_Het_model = spreg.GM_Error_Het(\n",
        "    # Dependent variable\n",
        "    datadisMap[dep_var_name].values,\n",
        "    # Independent variables\n",
        "    datadisMap[ind_vars_names].values,\n",
        "    # Spatial weights matrix\n",
        "    w=w_knn8,\n",
        "    # Dependent variable name\n",
        "    name_y=dep_var_name[0],\n",
        "    # Independent variable name\n",
        "    name_x=ind_vars_names,\n",
        ")\n",
        "print(error_Het_model.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d857a017",
      "metadata": {
        "id": "d857a017"
      },
      "source": [
        "### Exercise 10\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "    \n",
        "Use your three variables to carry out regression analysis (conventional and spatial).\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c037d70",
      "metadata": {
        "id": "3c037d70"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}